import streamlit as st
import os
import dotenv
import uuid
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage
from rag_methods import (
    get_documents_from_hal,
    stream_llm_response,
    stream_llm_rag_response,
)

dotenv.load_dotenv()

# Configuration de la page avec des √©l√©ments visuels
st.set_page_config(
    page_title="Recherche et Analyse de Documents Acad√©miques",
    page_icon="üìö",
    layout="centered",
    initial_sidebar_state="expanded"
)

# Titre principal avec style
st.markdown("<h1 style='text-align: center; color: #4CAF50;'>Recherche et Analyse de Documents Acad√©miques</h1>", unsafe_allow_html=True)
st.markdown("<hr>", unsafe_allow_html=True)

# Ajout de texte d'introduction
st.markdown("""
<div style='text-align: center;'>
    <p>Utilisez cette application pour trouver des documents acad√©miques selon un mot-cl√© et les analyser gr√¢ce √† un mod√®le de langage.</p>
    <p style='color: #6c757d;'>Propuls√© par GPT-4 et HAL</p>
</div>
""", unsafe_allow_html=True)

# Ins√©rer directement la cl√© API ici (c'est temporaire et non recommand√© pour la production)
api_key = "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"

# V√©rifier si la cl√© est bien pr√©sente
if not api_key:
    st.error("Cl√© API OpenAI manquante. Assurez-vous de l'ins√©rer correctement dans le fichier app.py.")
else:
    st.success("Cl√© API OpenAI charg√©e avec succ√®s.")

# Initialiser le mod√®le OpenAI
llm_stream = ChatOpenAI(
    api_key=api_key,  # Utiliser la cl√© API ici
    model_name="gpt-4",
    temperature=0.7,
    streaming=True,
)

# Initialisation de la session
if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())

if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "Bienvenue ! Je peux vous aider √† trouver des documents acad√©miques et √† en discuter ou les analyser."}
    ]

# Affichage des messages de la session avec mise en forme
for message in st.session_state.messages:
    role = "Utilisateur" if message["role"] == "user" else "Assistant"
    color = "#3498db" if message["role"] == "user" else "#2ecc71"
    st.markdown(f"<div style='background-color:{color};padding:10px;border-radius:10px;color:white;'><strong>{role}:</strong><br>{message['content']}</div>", unsafe_allow_html=True)
    st.markdown("<br>", unsafe_allow_html=True)

# Saisie d'un nouveau message par l'utilisateur
if prompt := st.chat_input("Votre message"):
    # V√©rification si le message contient un mot-cl√© pour la recherche de documents
    if "mot-cl√©" in prompt.lower():
        # Extraire le mot-cl√© du message
        keyword = prompt.split("mot-cl√©")[-1].strip()
        st.session_state.messages.append({"role": "user", "content": f"Recherche de documents sur le mot-cl√© '{keyword}'."})

        # Recherche de documents via HAL
        documents = get_documents_from_hal(keyword=keyword)

        if documents:
            for doc in documents:
                with st.chat_message("assistant"):
                    st.markdown(f"**Titre:** {doc['title_s']}\n\n**Auteur(s):** {doc['authFullName_s']}\n\n**R√©sum√©:** {doc['abstract_s']}\n\n**Date de publication:** {doc['producedDateY_i']}\n\n**Type de document:** {doc['docType_s']}")
                    st.session_state.messages.append({"role": "assistant", "content": f"**Titre:** {doc['title_s']}\n\n**Auteur(s):** {doc['authFullName_s']}\n\n**R√©sum√©:** {doc['abstract_s']}\n\n**Date de publication:** {doc['producedDateY_i']}\n\n**Type de document:** {doc['docType_s']}"})

            # Utilisation du LLM pour fournir une analyse du document
            with st.chat_message("assistant"):
                user_prompt = f"Voici un document sur {keyword}. Peux-tu en faire une analyse ?"
                messages = [HumanMessage(content=user_prompt)]

                full_response = ""
                placeholder = st.empty()  # Cr√©er un espace r√©serv√© pour accumuler et afficher les r√©sultats

                for chunk in stream_llm_rag_response(llm_stream, messages, documents):
                    full_response += chunk.content  # Ajout du texte sans espaces suppl√©mentaires
                    # Ajout d'une mise en forme du document avec deux sauts de ligne pour s√©parer les strophes
                    formatted_text = full_response.replace('\n', '  \n')
                    placeholder.markdown(formatted_text)  # Affichage du texte accumul√© progressivement avec la bonne mise en forme

                st.session_state.messages.append({"role": "assistant", "content": full_response})
        else:
            st.warning("Aucun document trouv√© avec les crit√®res sp√©cifi√©s.")
            st.session_state.messages.append({"role": "assistant", "content": "Aucun document trouv√© avec les crit√®res sp√©cifi√©s."})
    else:
        # Enregistrement du message utilisateur
        st.session_state.messages.append({"role": "user", "content": prompt})

        with st.chat_message("user"):
            st.markdown(prompt)

        # R√©ponse du LLM
        with st.chat_message("assistant"):
            # V√©rification que le prompt n'est pas vide
            if prompt:
                messages = [HumanMessage(content=prompt)]
                full_response = ""
                placeholder = st.empty()  # Espace r√©serv√© pour la r√©ponse

                # It√©ration sur le g√©n√©rateur pour afficher la r√©ponse du LLM
                for chunk in stream_llm_response(llm_stream, messages):
                    full_response += chunk  # Ajout du chunk sans espace suppl√©mentaire
                    # Ajout de la mise en forme avec des retours √† la ligne appropri√©s
                    formatted_text = full_response.replace('\n', '  \n')
                    placeholder.markdown(formatted_text)  # Affichage du chunk dans l'interface

                # Enregistrement de la r√©ponse compl√®te dans l'√©tat de session
                st.session_state.messages.append({"role": "assistant", "content": full_response})
            else:
                st.warning("Veuillez saisir un message avant de soumettre.")
